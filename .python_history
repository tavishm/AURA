import cv2
get_text_from_voice()
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
import function_for_motion
function_for_motion.move('up')
function_for_motion.move('down')
function_for_motion.move('exit')
import function_for_motion
function_for_motion.move('exit')
function_for_motion.move('down')
function_for_motion.move('left')
function_for_motion.move('exit')
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
'front' in 'front'
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
move('')
move('ft')
stt.move('')
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
import stt
stt.get_text_from_voice()
stt.move('')
import stt
stt.get_text_from_voice()
import stt
stt.move(''_
stt.move('')
import stt
stt.get_text_from_voice()
import system
import stt
stt.get_text_from_voice()
import stt
stt.move('')
import stt
stt.get_text_from_voice()
black_px()
get_text_from_voice()
cam_catch()
cam_catch(fps=2)
cam_catch(qual=(1,2))
cam_catch(fps=2)
cam_catch()
black_px()
blue_
blue_circular_signal(
)
blue_circular_signal()
blue_circular_signal(
cam_catch(fps=12, qual=(320,100))
cam_catch()
cam_catch(fps=240)
cam_catch(fps=)
2%2
4%2
0%2
import cv2
cap = cv2.VideoCapture(
cap = cv2.VideoCapture(0)
ret, img = cap.read()
cv2.imshow('img', img)
cv2.waitKey()
from pyzbar.pyzbar import decode
decode(img)
ret, img = cap.read()
cv2.imshow('img', img)
cv2.waitKey()
import cv2
cap = cv2.VideoCapture(0)
ret, img = cap.read()
from pyzbar.pyzbar import decode
decode(img)
cv2.imshow('img', img)
cv2.waitKey()
import cv2
from pyzbar.pyzbar import decode
cap = cv2.VideoCapture(0)
ret, img = cap.read()
decode(img)
cv2.imshow('img', img)
cv2.waitKey()
get_text_from_voice(
get_text_from_voice()
m
move('front')
move('front', per=35)
move('front', per=0)
move('front', per=50)
move('front', per=0)
get_text_from_voice()
move()
move('')
get_text_from_voice()
get_text_from_voice()\
get_text_from_voice()
move('front')
get_text_from_voice()
move('front')
move('')
move('front')
move('')
import qrtools
import pyqrtools
import pyqrcode
import pyqrtools
import pyqrcode\
import pyqrcode
qr = pyqrcode.create("we are out of potatoes")
qr.png("horn.png", scale=6)
import cv2
im = cv2.imread('horn.png')
cv2.imshow('im', im_
cv2.imshow('im', im)
cv2.waitKey()
data
data[]
list(data)
list(data)[0]
list(data)[0][1]
list(data)[0][0]
list(data)[0][0][1:]
list(data)[0][0][0:]
list(data)[0][0]
import requests
out = "how+are+you"
requests.get('http://192.168.1.110/matrix-server-bkd/wrapper.py?text='+out)
os.system('wget http://192.168.1.110/matrix-server-bkd/op.mp3')
import os
os.system('wget http://192.168.1.110/matrix-server-bkd/op.mp3')
os.system('omxplayer -o local op.mp3')
import requests
import os
requests.get('http://192.168.1.110/matrix-server-bkd/wrapper.py?text='+out)
out = 'play+news'
requests.get('http://192.168.1.110/matrix-server-bkd/wrapper.py?text='+out)
os.system('wget http://192.168.1.110/matrix-server-bkd/op.mp3')
os.system('omxplayer -o local op.mp3')
os.system('wget http://192.168.1.110/matrix-server-bkd/op.mp3')
os.system('omxplayer -o local op.mp3')
out = 'hello'
requests.get('http://192.168.1.110/matrix-server-bkd/wrapper.py?text='+out)
os.system('wget http://192.168.1.110/matrix-server-bkd/op.mp3')
os.system('omxplayer -o local op.mp3')
os.system('wget http://192.168.1.110/matrix-server-bkd/op.mp3')
os.system('omxplayer -o local op.mp3')
os.system('wget http://192.168.1.110/matrix-server-bkd/op.mp3')
os.system('omxplayer -o local op.mp3')
import requests
import os
import requests
import os
os.system('wget http://192.168.1.110/matrix-server-bkd/op.mp3')
os.system('omxplayer -o local op.mp3')
os.system('wget http://192.168.1.110/matrix-server-bkd/op.mp3')
get_text_from_voice(
get_text_from_voice()
b''.join([]
)
b''.join([])
b''.join([a,b])
b''.join([1,2])
''.join([1,2])
b''.join(['1','2'])
''.join(['1','2'])
b''.join([])
load_from_server()
river_config_proto.image.led.extend(everloop_image)
def glow_led(driver_config_proto, socket, everloop_image):
    driver_config_proto.image.led.extend(everloop_image)  # Store the Everloop image in driver configuration
    socket.send(driver_config_proto.SerializeToString())  # Send driver configuration through ZMQ socket
glow_led(load_from_server)
load_from_server()
adjust_brightness(18)
adjust_brightness(
recording_px()
status_green_px()
refresh_led_state()
start_recording_thread()
change_led_state()
change_led_state(recording_px()
change_led_state(recording_px)
load_from_server()
move('front'per=100)
move('front',per=100)
move('front',per=80)
move('front',per=50)
move('front',per=10)
move('front',per=5)
move('front',per=100)
move('front',per=60)
import move
import move from function_for_motor.py
from function_for_motion.py import move
import function_for_motion.py from move
move('')
move('back', per=100)
move('back', per=50)
move('back', per=60)
move('back', per=100)
move('back', per=50)
move('back', per=100)
move('')
move('back', per=100)
move('back', per=50)
move('back', per=100)
move('')
import re
data = re.sub('[^A-Za-z0-9 ]+', '', data).replace(' ', '+')
data = 'aura how are you?'
data = re.sub('[^A-Za-z0-9 ]+', '', data).replace(' ', '+')
data
data = re.sub('[^A-Za-z0-9 ]+', '', data).replace(' ', '+')
data
data = re.sub('[^A-Za-z0-9 ]+', '', data).replace(' ', '+')
data
data = re.sub('[^A-Za-z0-9 \+]+', '', data).replace(' ', '+')
data
data = re.sub('[^A-Za-z0-9 \+]+', '', data).replace(' ', '+')
data
data = 'aura how are you?'
data = re.sub('[^A-Za-z0-9 \+]+', '', data).replace(' ', '+')
data
data = re.sub('[^A-Za-z0-9 \+]+', '', data).replace(' ', '+')
data
data = re.sub('[^A-Za-z0-9 \+]+', '', data).replace(' ', '+')
data
import dlib
import cv2
v = cv2.VideoCapture(0)
ret, im = v.read()
cv2.imshow('im', im)
cv2.waitKey()
cv2.imwrite('images/face_detect_test.jpeg')
cv2.imwrite('images/face_detect_test.jpeg', im)
label
response
client.annotate_image(image)
client.annotate_image(image=image)
client.document_text_detection(image)
t = threading.Thread(target=show,args=([frame]))
t.start()
cap = cv2.VideoCapture(0)
ret, frame = cap.read()
cv2.imwrite('resources/wakeupcat.jpg', frame)
t = threading.Thread(target=show,args=([frame]))
t.start()
t = threading.Thread(target=show,args=([frame]))
t.start()
frame
cap = cv2.VideoCapture(0)
ret, frame = cap.read()
cv2.imwrite('resources/wakeupcat.jpg', frame)
t = threading.Thread(target=show,args=([frame]))
t.start()
cap = cv2.VideoCapture(0)
ret, frame = cap.read()
cap = cv2.VideoCapture(0)
ret, frame = cap.read()
cv2.imwrite('resources/wakeupcat.jpg', frame)
t = threading.Thread(target=show,args=([frame]))
t.start()
file_name = os.path.abspath('resources/wakeupcat.jpg')
# Loads the image into memory
with io.open(file_name, 'rb') as image_file:
    content = image_file.read()
image = types.Image(content=content)
# Performs label detection on the image file
response = client.label_detection(image=image)
labels = response.label_annotations
print('Labels:')
for label in labels:
    print(label.description)
fin_func('hello')
fin_func('hello how are you')
speak_text('hello', speak=True)
speak_text('hello how are you', speak=True)
speak_text('play photograph', speak=True)
if main:
	print('h')
if __main:
	print('h')
speak_text(
speak_text()
speak_text("play kajara re")
speak_text("play kajara re", speak=true)
speak_text("play kajara re", speak=True)
max(os.listdir('.'),key=os.path.getctime)
speak_text("play kajara re", speak=true)
speak_text("play kajara re", speak=True)
max(os.listdir('.'),key=os.path.getctime)
import os
max(os.listdir('.'),key=os.path.getctime)
os.system('mv '+max(os.listdir('.'),key=os.path.getctime)+' op.mp3')
max(os.listdir('.'),key=os.path.getctime)
os.system('mv '+max(os.listdir('.'),key=os.path.getctime)+' op.mp3')
max(os.listdir('.'),key=os.path.getctime)
os.rename(max(os.listdir('.'),key=os.path.getctime), 'op.mp3')
max(os.listdir('.'),key=os.path.getctime)
os.rename(max(os.listdir('.'),key=os.path.getctime), 'op.mp3')
os.system('omxplayer -o local op.mp3')
ydl.download(['https://www.youtube.com/watch?v=ev8cKdrdA4s'])
import youtube_dl
ydl = youtube_dl.YoutubeDL(ydl_opts)
ydl_opts = {
            'format': 'bestaudio/best',
            'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '100',
            }],
        }
ydl = youtube_dl.YoutubeDL(ydl_opts)
ydl.download(['https://www.youtube.com/watch?v=ev8cKdrdA4s'])
ydl.extract_info('https://www.youtube.com/watch?v=ev8cKdrdA4s', download=True)
speak_text("hello", speak=True)
speak_text("hello, how are you", speak=True)
speak_text("hello how are you", speak=True)
speak_text("what are you doing", speak=True)
speak_text("hello how are you", speak=True)
frame.shape
cv2.imshow(frame)
cv2.imshow(frame, 'im')
cv2.imshow('im', frame)
cv2.waitKey()
frame.shape
frame.shape(1)
frame.shape[0]
frame.shape[1]
move('right')
move('')
face
faces
twid
rzones
rzoneswid
lzoneswid
face_
face_mid
speak_text('hello')
speak_text('hello', speak=true)
speak_text('hello', speak=True)
speak_text('hello, how are you', speak=True)
speak_text('how are you', speak=True)
speak_text('how can you help me?', speak=True)
speak_text('play photograph', speak=True)
os.path.isfile('')
speak_text('play photograph', speak=True)
speak_text('how can you help me?', speak=True)
speak_text('aura play photograph', speak=True)
import sys
sys.path.append('nlp/')
import wrapper
wrapper.speak_text('play photograph')
import wrapper
wrapper.speak_text('hello how are you', speak=True)
58.181*11
407/58
lzoneswid
lzones
232/58
mzones
547.0-407.27272727272725
58.18181818181818*rzones
rzones
232.72727272727272/139.72727272727275
speak_text('hello', speak_text=True)
speak_text('hello', speak=True)
speak_text('play photograph', pseak=True)
speak_text('play photograph', speak=True)
speak_text('play laila main laila', speak=True)
speak_text('hello how are you', speak=True)
speak_text('what is the solar system')'
speak_text('what is the solar system')
speak_text('what is the solar system', speak=True)
speak_text('tell me the solar system', speak=True)
speak_text('tell me about the solar system', speak=True)
speak_text('define solar system', speak=True)
speak_text('tell me about solar system', speak=True)
speak_text('tell me about the solar system', speak=True)
speak_text('time', speak=True)
speak_text('My leg is paining', speak=True)
speak_text('play the news', speak=True)
import os
import shutil
from shutil import copyfile
speak_text('play news', speak=True)
import os
os.path.getmtime('play_news.mp3')
time()
import time
time.time()
time.time() - os.path.getmtime('play_news.mp3')
time.time() - os.path.getmtime('play_news.mp3') > 180
time.time() - os.path.getmtime('play_news.mp3') < 180
3600*24
speak_text('play news', speak=True)
3600*24
speak_text('play news', speak=True)
speak_text('play kajrare', speak=True)
speak_text('play tera ghata', speak=True)
speak_text('play news', speak=True)
speak_text('what is mango', speak=True)
speak_text('mango', speak=True)
speak_text('what is taj mahal', speak=True)
speak_text('My leg is paining', speak=True)
speak_text('what is taj mahal', speak=True)
speak_text('what is the taj mahal', speak=True)
speak_text('what is solar system', speak=True)
speak_text('what is orange', speak=True)
speak_text('what is mango', speak=True)
frame.shape
np.shape(frame)
cap
cap = cv2.VideoCapture(0)
ret, frame = cap.read()
frame.shape
import rpi.GPIO
import GPIO.rpi
import RPi.GPIO
go('left')
go('')
from keypress import get_key
from matrix_lite import gpio
for i in (0,1,2,3,4,5,6,7):
    gpio.setFunction(i, 'DIGITAL')
    gpio.setMode(i, "output")
gpio.setDigital(0,"ON")
gpio.setDigital(1,"OFF")
gpio.setDigital(2,"ON")
gpio.setDigital(3,"OFF")
gpio.setDigital(3,"ON")
gpio.setDigital(3,"OFF")
gpio.setDigital(2,"OFF")
gpio.setDigital(0,"OFF")
gpio.setDigital(2,"ON")
gpio.setDigital(2,"OFF")
gpio.setDigital(4,"ON")
gpio.setDigital(4,"OFF")
gpio.setDigital(5,"ON")
gpio.setDigital(5,"OFF")
gpio.setDigital(3,"ON")
gpio.setDigital(3,"OFF")
gpio.setDigital(6,"ON")
gpio.setDigital(6,"OFF")
gpio.setDigital(7,"ON")
gpio.setDigital(7,"OFF")
gpio.setDigital(0,"ON")
gpio.setDigital(0,"OFF")
gpio.setDigital(1,"ON")
gpio.setDigital(1,"OFF")
gpio.setDigital(6,"ON")
gpio.setDigital(6,"OFF")
gpio.setDigital(7,"ON")
gpio.setDigital(7,"OFF")
gpio.setDigital(4,"ON")
gpio.setDigital(4,"OFF")
gpio.setDigital(5,"ON")
gpio.setDigital(5,"OFF")
gpio.setDigital(2,"ON")
gpio.setDigital(2,"OFF")
gpio.setDigital(3,"ON")
gpio.setDigital(3,"OFF")
motor_gpio = {}
motor_gpio{"FR"} = (0, 1)
motor_gpio{"FL"} = (6, 7)
motor_gpio{"RR"} = (5, 4)
motor_gpio{"RL"} = (3, 2)
motor_gpio = {}
motor_gpio["FR"] = (0, 1)
motor_gpio["FL"] = (6, 7)
motor_gpio["RR"] = (5, 4)
motor_gpio["RL"] = (3, 2)
motor_gpio
motor_gpio['FL']
motor_gpio['FL'][0]
motor_gpio['FL'][1]
import PIL
from PIL import Image
Image.open('sleeping.gif')
im = Image.open('sleeping.gif')
im.show(
im.show()
im = Image.open('sleeping.gif')
im.show()
im = Image.open('sleephtrhing.gif')
im = Image.open('sleeping.gif')
im.show()
import cv2
import numpy as np
im = cv2.imread('sleeping.gif')
cv2.imshow('im', im)
im
im = cv2.imread('sleeping.gif')
im
im = Image.open('sleeping.gif')
index = 1
import ImageSequence from PIL
from PIL import ImageSequence 
for frame in ImageSequence.Iterator(im):
	frame.show()
	index+=1
frame
frame.show(
)
frame.show()
-10/abs(-10)
res.type()
lif
a = (-1, 1, 1, -1)
abs(a)
a = [-1, 1, 1, -1]
abs(a)
s = '  lfdfg dfdfd   dfgfgdfd   '
ss = '  lfdfg dfdfd   dfgfgdfd   '
ss.strip().split()
ss.strip().split()[-1]
ss = '  dfgfgdfd   '
ss.strip().split()
ss.strip().split()[-1]
ss == 'down' or ss == 'up' or ss == 'right' or ss == 'left' or 'stop'
ss = 'dfgdf'
ss == 'down' or ss == 'up' or ss == 'right' or ss == 'left' or 'stop'
while True: pass
if 'OQ' == 'OQ'
'OQ' == 'OQ'
'OQ' == '0Q'
while True: pass
import requests
requests.get('kanhamadeaappin1dayandthispasswordisquiteuniqueithinkbutaappin1dayisgreatanditisenoughrandomkanhaanywaypastethisrandomkeythankyoufullstopandpleasedontmodifythisatallthankyoufullstop')
requests.get('http://brahm.ai/matrix-server-bkd/get_med.py?key=kanhamadeaappin1dayandthispasswordisquiteuniqueithinkbutaappin1dayisgreatanditisenoughrandomkanhaanywaypastethisrandomkeythankyoufullstopandpleasedontmodifythisatallthankyoufullstop')
res = requests.get('http://brahm.ai/matrix-server-bkd/get_med.py?key=kanhamadeaappin1dayandthispasswordisquiteuniqueithinkbutaappin1dayisgreatanditisenoughrandomkanhaanywaypastethisrandomkeythankyoufullstopandpleasedontmodifythisatallthankyoufullstop')
res = res.text
res
res[res.find('<body>'):]
res1 = res[res.find('<body>'):]
res1 = res1[:res1.find('<body>')]
res1
res1 = res1[:res1.find('<\body>')]
res1
res1 = res[res.find('<body>'):]
res1
res1 = res1[:res1.find('<\body>')]
res1
res1 = res1[:res1.find('</body>')]
res1
res[res.find('<body>'):]
res[res.find('<body>'):][:res:[:res.find('<body>')].find('</body>')]
res[res.find('<body>'):][:res[:res.find('<body>')].find('</body>')]
res1 = res[res.find('<body>'):]
res1 = res1[:res1.find('</body>')]
res1
res1 = res[res.find('<body>'):]
res1
reslist = res1.split('\n')
reslist
res1 = res1[:res1.find('</body>')]
res1
reslist
reslist = res1.split('\n')
reslist
when_nex_med()
requests.get('kanhamadeaappin1dayandthispasswordisquiteuniqueithinkbutaappin1dayisgreatanditisenoughrandomkanhaanywaypastethisrandomkeythankyoufullstopandpleasedontmodifythisatallthankyoufullstop')
import requests
requests.get('kanhamadeaappin1dayandthispasswordisquiteuniqueithinkbutaappin1dayisgreatanditisenoughrandomkanhaanywaypastethisrandomkeythankyoufullstopandpleasedontmodifythisatallthankyoufullstop')
res = requests.get('http://brahm.ai/matrix-server-bkd/get_med.py?key=kanhamadeaappin1dayandthispasswordisquiteuniqueithinkbutaappin1dayisgreatanditisenoughrandomkanhaanywaypastethisrandomkeythankyoufullstopandpleasedontmodifythisatallthankyoufullstop')
res = res.text
import json
json.loads(res)
mdict = json.loads(res)
mdict = json.dumps(res)
mdict
import json
import requests
res = requests.get('http://brahm.ai/matrix-server-bkd/get_med.py?key=kanhamadeaappin1dayandthispasswordisquiteuniqueithinkbutaappin1dayisgreatanditisenoughrandomkanhaanywaypastethisrandomkeythankyoufullstopandpleasedontmodifythisatallthankyoufullstop')
res
res = res.txt
res = res.text
res
speak_text('hello')
speak_text('hello', speak=True)
speak_text('play the news', speak=True)
speak_text('hello', speak=True)
st = '2019-12-21'
strptime(st)
import datetime
datetime.datetime.strptime(str, %Y-%m-%d)
datetime.datetime.strptime(str, '%Y-%m-%d')
datetime.datetime.strptime(st, '%Y-%m-%d')
datetime.datetime.strptime(st, '%Y-%m-%m')
datetime.datetime.strptime(st, '%Y-%ds-%m')
datetime.datetime.strptime(st, '%Y-%d-%m')
datetime.datetime.strptime(st, '%Y-%m-%d')
when_nex_med()
speak_text('when should i take the next medicines?', speak=True)
speak_text('when should i take next medicines?', speak=True)
speak_text('when is the next medication reminder?', speak=True)
speak_text('when should i take the next medicines?', speak=True)
import screeninfo
screenid = 0
screeninfo.get_monitors()[sreenid]
screeninfo.get_monitors()[screenid]
screeninfo.get_monitors()
frame.sh
frame.shape
frame.size
np.shape(frame)
frame
import op_cv_gif_view
from op_cv_gif_view import write_fifo
import op_cv_gif_view
op_cv_gif_view.write_in_fifo('thumbs up')
op_cv_gif_view.write_in_fifo('thank god')
import op_cv_gif_view
op_cv_gif_view.write_in_fifo('thank god')
op_cv_gif_view.write_in_fifo('music')
import os
os.system('watch ls')
import op_cv_gif_view
op_cv_gif_view.write_in_fifo("working-hard")
from op_cv_gif_view import write_in_fifo
write_in_fifo("listening")
from edit_conf_state import set_state
set_state("sleeping")
import edit_conf_state
from edit_conf_state import set_state
set_state("listening")
import op_cv_gif_view
op_cv_gif_view.write_in_fifo('talking')
op_cv_gif_view.write_in_fifo('talking_2')
op_cv_gif_view.write_in_fifo('talking_2_')
op_cv_gif_view.write_in_fifo('talking')
op_cv_gif_view.write_in_fifo('smiling-listening')
import op_cv_gif_view
op_cv_gif_view.write_in_fifo('talking')
op_cv_gif_view.write_in_fifo('smiling-listening')
op_cv_gif_view.write_in_fifo('talking')
op_cv_gif_view.write_in_fifo('smiling-listening')
op_cv_gif_view.write_in_fifo('talking')
op_cv_gif_view.write_in_fifo('listening')
speak_text("when should i take my next medicines", speak=True)
200*1000
200000/30
200000/30/24
490/277.77777777777777
1.764*60
from op_cv_gif_view
from op_cv_gif_view import write_in_fifo
write_in_fifo("listening")
write_in_fifo("sleeping")
import numpy as np
import sys
import os
import cb2
import cv2
win = 'ffname'
img = cv2.imread('user-male.png', cv2.IMREAD_COLOR)
cv2.imshow(ffname, img)
cv2.imshow(win, img)
cv2.moveWindow(win,0,0)
cv2.waitkey()
cv2.waitKey()
speak_text('when should i take my next medicines', speak=True)
1879+724+661
speak_text('when should i take my next medicines', speak=True)
30*26
780/60
1.7*12
20.4*3
20+20+120
